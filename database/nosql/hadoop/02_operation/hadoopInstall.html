<!DOCTYPE html>
<html lang="zh-cn">
<head prefix="og: http://ogp.me/ns#">
  <meta charset="utf-8">
  <title>Hadoop Install & wordcount test | BoobooWei</title>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  <!-- Canonical links -->
  <link rel="canonical" href="http://www.toberoot.com/database/nosql/hadoop/02_operation/hadoopInstall.html">
  <!-- Alternative links -->
  
    
      <link rel="alternative" hreflang="zh-cn" href="http://www.toberoot.com/zh-cn/database/nosql/hadoop/02_operation/hadoopInstall">
    
  
  <!-- Icon -->
  <link rel="apple-touch-icon" sizes="57x57" href="/icon/apple-touch-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/icon/apple-touch-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/icon/apple-touch-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/icon/apple-touch-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/icon/apple-touch-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/icon/apple-touch-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/icon/apple-touch-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/icon/apple-touch-icon-152x152.png">
  <link rel="icon" type="image/png" href="/icon/favicon-196x196.png" sizes="196x196">
  <link rel="icon" type="image/png" href="/icon/favicon-160x160.png" sizes="160x160">
  <link rel="icon" type="image/png" href="/icon/favicon-96x96.png" sizes="96x96">
  <link rel="icon" type="image/png" href="/icon/favicon-16x16.png" sizes="16x16">
  <link rel="icon" type="image/png" href="/icon/favicon-32x32.png" sizes="32x32">
  <meta name="msapplication-TileColor" content="#2f83cd">
  <meta name="msapplication-TileImage" content="/icon/mstile-144x144.png">
  <!-- CSS -->
  <!-- build:css build/css/navy.css -->
  
<link rel="stylesheet" href="/css/navy.css">

  <!-- endbuild -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-lato@0.0.75/index.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.3.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css">
  <!-- RSS -->
  <link rel="alternate" href="/atom.xml" title="BoobooWei" type="application/atom+xml">
  <!-- Open Graph -->
  <meta name="description" content="环境介绍OS:rhel7.2 mastera    172.25.0.11 nameserver(8020 50070)     resourcemanager（8032 8030 8088 8031 8033 ）jobhistory(10020 19888)     slavea    172.25.0.13 datanode           nodemanager slaveb     1">
<meta property="og:type" content="website">
<meta property="og:title" content="Hadoop Install &amp; wordcount test">
<meta property="og:url" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/hadoopInstall">
<meta property="og:site_name" content="BoobooWei">
<meta property="og:description" content="环境介绍OS:rhel7.2 mastera    172.25.0.11 nameserver(8020 50070)     resourcemanager（8032 8030 8088 8031 8033 ）jobhistory(10020 19888)     slavea    172.25.0.13 datanode           nodemanager slaveb     1">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/01.png">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/02.png">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/03.png">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/04.png">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/05.png">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/06.png">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/07.png">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/08.png">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/09.png">
<meta property="og:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/10.png">
<meta property="article:published_time" content="2022-03-22T03:27:47.576Z">
<meta property="article:modified_time" content="2022-03-22T03:27:47.576Z">
<meta property="article:author" content="魏亚萍">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://www.toberoot.com/database/nosql/hadoop/02_operation/pic/01.png">
<meta property="fb:admins" content="100000247608790">
  <!-- Google Analytics -->
  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-48498357-3', 'auto');
  ga('send', 'pageview');
</script>

  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
     (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-6482217598104186",
          enable_page_level_ads: true
     });
  </script>
  <!-- at the end of the HEAD -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
<meta name="generator" content="Hexo 6.1.0"></head>

<body>
  <div id="container">
    <header id="header" class="wrapper">
  <div id="header-inner" class="inner">
    <h1 id="logo-wrap">
      <a href='/' id="logo">ToBeRoot</a>
    </h1>
    <nav id="main-nav">
      <a href="/api/" class="main-nav-link">MySQL8.0</a><a href="/database/" class="main-nav-link">Database</a><a href="/devops/" class="main-nav-link">DevOps</a><a href="/linux/" class="main-nav-link">Linux</a><a href="/cloud/" class="main-nav-link">Cloud</a><a href="/mse/" class="main-nav-link">MSE</a><a href="/singapore/" class="main-nav-link">Singapore</a><a href="/news/" class="main-nav-link">News</a>
      <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/BoobooWei" class="main-nav-link"><i class="fa fa-github-alt"></i></a>
      <div id="search-input-wrap">
        <div id="search-input-icon">
          <i class="fa fa-search"></i>
        </div>
        <input type="search" id="search-input" placeholder="Search...">
      </div>
    </nav>
    <div id="lang-select-wrap">
      <a href="/themes/" class="main-nav-link"><label id="lang-select-label"><i class="fa fa-globe"></i><span>技术广角</span></label></a>
    </div>


    <a id="mobile-nav-toggle">
      <span class="mobile-nav-toggle-bar"></span>
      <span class="mobile-nav-toggle-bar"></span>
      <span class="mobile-nav-toggle-bar"></span>
    </a>
  </div>
</header>

    <div id="content-wrap">
  <div id="content" class="wrapper">
    <div id="content-inner">
      <article class="article-container" itemscope itemtype="http://schema.org/Article">
        <div class="article-inner">
          <div class="article">
            <div class="inner">
              <header class="article-header">
                <h1 class="article-title" itemprop="name">Hadoop Install & wordcount test</h1>
                <a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/booboowei/site/edit/master/source/database/nosql/hadoop/02_operation/hadoopInstall.md" class="article-edit-link" title="改进本文"><i class="fa fa-pencil"></i></a>
              </header>
              <div class="article-content" itemprop="articleBody">
                <h2 id="环境介绍" class="article-heading"><a href="#环境介绍" class="headerlink" title="环境介绍"></a>环境介绍<a class="article-anchor" href="#环境介绍" aria-hidden="true"></a></h2><p>OS:rhel7.2</p>
<p>mastera    172.25.0.11 nameserver(8020 50070)     resourcemanager（8032 8030 8088 8031 8033 ）jobhistory(10020 19888)    </p>
<p>slavea    172.25.0.13 datanode           nodemanager</p>
<p>slaveb     172.25.0.14 datanode        nodemanager</p>
<h2 id="初始化环境脚本" class="article-heading"><a href="#初始化环境脚本" class="headerlink" title="初始化环境脚本"></a>初始化环境脚本<a class="article-anchor" href="#初始化环境脚本" aria-hidden="true"></a></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">A1()&#123;</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">对root用户创建无密钥登陆</span></span><br><span class="line">	for i in 11 13 14;do ssh-copy-id root@172.25.0.$i;done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">A2()&#123;</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">虚拟机创建hadoop用户密码为uplooking</span></span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">虚拟机安装vim wget net-tools</span></span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">真机将公钥拷贝到虚拟机</span></span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">虚拟机hadoop用户新建公钥私钥</span></span><br><span class="line"></span><br><span class="line">	for i in 11 13 14</span><br><span class="line">	do </span><br><span class="line">		ssh root@172.25.0.$i &quot;useradd hadoop ; echo uplooking|passwd --stdin hadoop ; yum install -y 	vim net-tools wget ;systemctl stop firewalld ; setenforce 0;sed -i &#x27;s/SELINUX=enforcing/SELINUX=disabled/&#x27; /etc/selinux/config&quot;</span><br><span class="line">		ssh-copy-id hadoop@172.25.0.$i</span><br><span class="line">	done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">A3()&#123;</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">虚拟机之间无密钥访问，包括自己</span></span><br><span class="line">	for i in 11 13 14</span><br><span class="line">	do </span><br><span class="line">		ssh hadoop@172.25.0.$i &quot;ssh-keygen&quot;</span><br><span class="line">	done</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">将虚拟机的公钥保存到真机的tmp.txt中</span></span><br><span class="line">	(for i in 11 13 14;do ssh hadoop@172.25.0.$i &quot;cat /home/hadoop/.ssh/id_rsa.pub&quot;;done )&gt; tmp.txt</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">将保存所有虚拟机公钥的文件复制到虚拟机中，并追加到authorized_keys文件中</span></span><br><span class="line">	for i in 11 13 14</span><br><span class="line">	do </span><br><span class="line">		scp tmp.txt  hadoop@172.25.0.$i:~ </span><br><span class="line">		ssh hadoop@172.25.0.$i &quot;cat ~/tmp.txt &gt;&gt; /home/hadoop/.ssh/authorized_keys&quot;</span><br><span class="line">	done</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">mastera虚拟机访问自己会产生known_hosts</span></span><br><span class="line">	ssh hadoop@172.25.0.11 &quot;ssh hadoop@172.25.0.11;cat ~/.ssh/known_hosts&quot; &gt; known_hosts.tmp</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">根据known_hosts去写所有虚拟机的known_hosts并保存在真机的known_hosts.tmp文件中</span></span><br><span class="line">	cat &gt; known_hosts.tmp &lt;&lt; ENDF</span><br><span class="line">172.25.0.11 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBL58xGGAGvl4PmE+QXczZ4zmj0OEaaC/jLB0VmiO8ICCIzH825NZrQCWEJAvx+WwEQY7T0cGSvDUzoXOcjr/81c=</span><br><span class="line">172.25.0.13 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBL58xGGAGvl4PmE+QXczZ4zmj0OEaaC/jLB0VmiO8ICCIzH825NZrQCWEJAvx+WwEQY7T0cGSvDUzoXOcjr/81c=</span><br><span class="line">172.25.0.14 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBL58xGGAGvl4PmE+QXczZ4zmj0OEaaC/jLB0VmiO8ICCIzH825NZrQCWEJAvx+WwEQY7T0cGSvDUzoXOcjr/81c=</span><br><span class="line">ENDF</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">将临时文件拷贝到虚拟机即可</span></span><br><span class="line">	for i in 11 13 14;do scp known_hosts.tmp  hadoop@172.25.0.$i:~ ;done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">A4()&#123;</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">创建文件系统给hadoop使用 20G /hadoop</span></span><br><span class="line">	cat &gt; hadoop_file.sh &lt;&lt; endfile</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">cat &gt; fdisk.tmp &lt;&lt; ENDF</span><br><span class="line">n</span><br><span class="line">p</span><br><span class="line">1</span><br><span class="line">2048</span><br><span class="line">41943039</span><br><span class="line">w</span><br><span class="line">ENDF</span><br><span class="line"></span><br><span class="line">fdisk /dev/vdb &lt; fdisk.tmp</span><br><span class="line">mkfs.xfs /dev/vdb1</span><br><span class="line">mkdir /hadoop</span><br><span class="line">mount /dev/vdb1 /hadoop</span><br><span class="line">chown hadoop. /hadoop/ -R</span><br><span class="line">cat &gt;&gt; /etc/fstab &lt;&lt; ENDF</span><br><span class="line">/dev/vdb1 		/hadoop  		xfs	defaults        0 0</span><br><span class="line">ENDF</span><br><span class="line">mount -a</span><br><span class="line">endfile</span><br><span class="line"></span><br><span class="line">	for i in 11 13 14</span><br><span class="line">	do </span><br><span class="line">		scp hadoop_file.sh  root@172.25.0.$i:~</span><br><span class="line">		ssh  root@172.25.0.$i &quot;bash hadoop_file.sh&quot;</span><br><span class="line">	done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">A5()&#123;</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">下载hadoop的安装包</span></span><br><span class="line">	ssh hadoop@172.25.0.11 &quot;cd /hadoop ; wget http://classroom.example.com/content/hadoop/cdb5.tar ;wget http://classroom.example.com/content/hadoop/jdk.tar&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main()&#123;</span><br><span class="line">A1</span><br><span class="line">A2</span><br><span class="line">A3</span><br><span class="line">A4</span><br><span class="line">A5</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">main</span><br></pre></td></tr></table></figure>
<h2 id="Install-JDK-amp-Hadoop" class="article-heading"><a href="#Install-JDK-amp-Hadoop" class="headerlink" title="Install JDK &amp; Hadoop"></a>Install JDK &amp; Hadoop<a class="article-anchor" href="#Install-JDK-amp-Hadoop" aria-hidden="true"></a></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">以下操作在mastera上执行</span></span><br><span class="line">B1()&#123;</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">解压缩</span></span><br><span class="line">	cd /hadoop</span><br><span class="line">	tar -xf jdk.tar </span><br><span class="line">	tar -xf cdb5.tar</span><br><span class="line">	rm -rf jdk.tar</span><br><span class="line">	rm -rf cdb5.tar</span><br><span class="line">	rm -rf jdk/jdk-7u79-windows-x64.exe</span><br><span class="line">	cd jdk</span><br><span class="line">	tar -xf jdk-7u79-linux-x64.tar.gz</span><br><span class="line">	rm -rf jdk-7u79-linux-x64.tar.gz</span><br><span class="line">	cd /hadoop/cdb5/</span><br><span class="line">	tar -xf hadoop-2.5.0-cdh5.3.6.tar.gz -C /hadoop</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">安装jdk并宣告java家目录</span></span><br><span class="line">	mv /hadoop/jdk /usr/local/</span><br><span class="line">	echo &quot;export JAVA_HOME=/usr/local/jdk/jdk1.7.0_79/&quot; &gt;&gt; /etc/bashrc</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">安装hadoop，添加hadoop家目录和可执行路径</span></span><br><span class="line">	echo &quot;export HD_HOME=/hadoop/hadoop-2.5.0-cdh5.3.6&quot; &gt;&gt; /etc/bashrc</span><br><span class="line">	echo &quot;export PATH=$&#123;PATH&#125;:$&#123;HD_HOME&#125;/bin:$&#123;HD_HOME&#125;/sbin:$&#123;JAVA_HOME&#125;/bin&quot; &gt;&gt; /etc/bashrc</span><br><span class="line">	source /etc/bashrc</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">B1</span><br></pre></td></tr></table></figure>
<h2 id="Hadoop配置文件" class="article-heading"><a href="#Hadoop配置文件" class="headerlink" title="Hadoop配置文件"></a>Hadoop配置文件<a class="article-anchor" href="#Hadoop配置文件" aria-hidden="true"></a></h2><ul>
<li>core-site.xml模板     share/doc/hadoop-project-dist/hadoop-common/core-default.xml</li>
<li>hdfs-site.xml模板    share/doc/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</li>
<li>yarn-site.xml模板     share/doc/hadoop-yarn/hadoop-yarn-common/yarn-default.xml</li>
<li>mapred-site.xml模板    share/doc/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml</li>
</ul>
<p>列出核心内容</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">B2()&#123;</span><br><span class="line"><span class="meta prompt_">	# </span><span class="language-bash">集群的配置文件</span></span><br><span class="line">	cd $&#123;HD_HOME&#125;/etc/hadoop</span><br><span class="line">	cat &gt; core-site.xml &lt;&lt; ENDF</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://172.25.0.11:8020&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">ENDF</span><br><span class="line"></span><br><span class="line">	cat &gt; hdfs-site.xml &lt;&lt; ENDF</span><br><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;file:/hadoop/hfs/name&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;file:/hadoop/hfs/data&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;  </span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;2&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br><span class="line">ENDF</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">yarn-site.xml 中注意两点</span><br><span class="line">yarn.resourcemanager.hostname=172.25.0.11</span><br><span class="line">yarn.nodemanager.aux-services=mapreduce_shuffle</span><br><span class="line"></span><br><span class="line">mapred-site.xml</span><br><span class="line">mapreduce.framework.name=yarn</span><br><span class="line"></span><br><span class="line">echo mastera0 &gt; masters</span><br><span class="line">echo slavea0 &gt; slaves</span><br><span class="line">echo slaveb0 &gt;&gt; slaves</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">C1()&#123;</span><br><span class="line">for i in 13 14 ; do scp -r  root@172.25.0.11:/usr/local/jdk root@172.25.0.$i:/usr/local;done</span><br><span class="line">for i in 13 14 ; do scp -r  hadoop@172.25.0.11:/hadoop/hadoop-2.5.0-cdh5.3.6 hadoop@172.25.0.$i:/hadoop;done</span><br><span class="line">for i in 11 13 14 ; do ssh root@172.25.0.$i &quot;chown hadoop. /hadoop -R&quot;;done</span><br><span class="line">for i in 13 14 ; do scp -r  root@172.25.0.11:/etc/bashrc root@172.25.0.$i:/etc/bashrc;done</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">B1</span><br><span class="line">B2</span><br><span class="line">C1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="wordcount-测试" class="article-heading"><a href="#wordcount-测试" class="headerlink" title="wordcount 测试"></a>wordcount 测试<a class="article-anchor" href="#wordcount-测试" aria-hidden="true"></a></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">格式化namenode</span></span><br><span class="line">hdfs namenode -format</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动hdfs和mapreduce（yarn）</span></span><br><span class="line">start-dfs.sh</span><br><span class="line">sbin/start-yarn.sh</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">start-all.sh</span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">启动hisotryserver</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">sbin/mr-jobhistory-daemon.sh stop historyserver</span></span><br><span class="line">sbin/mr-jobhistory-daemon.sh start historyserver</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看java进程</span></span><br><span class="line">jps</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">第归创建测试目录</span></span><br><span class="line">hdfs dfs -mkdir -p /booboo/input</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将单词文件放入测试目录</span></span><br><span class="line"><span class="meta prompt_">cat&gt; </span><span class="language-bash">words &lt;&lt; <span class="string">ENDF</span></span></span><br><span class="line">hello tom</span><br><span class="line">hello jack</span><br><span class="line">hello superman</span><br><span class="line">superman is me</span><br><span class="line">batman vs superman</span><br><span class="line">ENDF</span><br><span class="line"></span><br><span class="line">hdfs dfs -put words /booboo/input</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="string">开始测试，并将结果输出到制定目录</span></span></span><br><span class="line">yarn jar hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0-cdh5.3.6.jar wordcount /booboo/input /booboo/output1</span><br></pre></td></tr></table></figure>
<h2 id="详细操作留档" class="article-heading"><a href="#详细操作留档" class="headerlink" title="详细操作留档"></a>详细操作留档<a class="article-anchor" href="#详细操作留档" aria-hidden="true"></a></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[hadoop@mastera0 ~]$ hdfs namenode -format</span><br><span class="line">17/04/05 14:48:22 INFO namenode.NameNode: STARTUP_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">STARTUP_MSG: Starting NameNode</span><br><span class="line">STARTUP_MSG:   host = mastera0.example.com/172.25.0.11</span><br><span class="line">STARTUP_MSG:   args = [-format]</span><br><span class="line">STARTUP_MSG:   version = 2.5.0-cdh5.3.6</span><br><span class="line">STARTUP_MSG:   classpath = /hadoop/hadoop-2.5.0-cdh5.3.6/etc/hadoop:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/guava-11.0.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jsch-0.1.42.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-digester-1.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/xz-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jetty-util-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-collections-3.2.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/xmlenc-0.52.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jersey-core-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/asm-3.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-el-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-codec-1.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jersey-json-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-lang-2.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/curator-framework-2.6.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/hadoop-auth-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jsr305-1.3.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/avro-1.7.6-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-net-3.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/junit-4.11.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/activation-1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/servlet-api-2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/hadoop-annotations-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jersey-server-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/zookeeper-3.4.5-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/curator-client-2.6.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jetty-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-io-2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/hadoop-common-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/hadoop-nfs-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/hadoop-common-2.5.0-cdh5.3.6-tests.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/asm-3.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-el-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jetty-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/hadoop-hdfs-2.5.0-cdh5.3.6-tests.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/hadoop-hdfs-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jline-0.9.94.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/xz-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jettison-1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/asm-3.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/guice-3.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jackson-xc-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/activation-1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/zookeeper-3.4.5-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jackson-jaxrs-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jetty-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-client-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-common-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-api-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-common-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/avro-1.7.6-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.6-tests.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.0-cdh5.3.6.jar:/contrib/capacity-scheduler/*.jar</span><br><span class="line">STARTUP_MSG:   build = http://github.com/cloudera/hadoop -r 6743ef286bfdd317b600adbdb154f982cf2fac7a; compiled by &#x27;jenkins&#x27; on 2015-07-28T22:14Z</span><br><span class="line">STARTUP_MSG:   java = 1.7.0_79</span><br><span class="line">************************************************************/</span><br><span class="line">17/04/05 14:48:22 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]</span><br><span class="line">17/04/05 14:48:22 INFO namenode.NameNode: createNameNode [-format]</span><br><span class="line">17/04/05 14:48:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Formatting using clusterid: CID-954f4053-15e7-4bda-b7de-18f0cf9397f8</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: No KeyProvider found.</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: fsLock is fair:true</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: The block deletion will start around 2017 Apr 05 14:48:23</span><br><span class="line">17/04/05 14:48:23 INFO util.GSet: Computing capacity for map BlocksMap</span><br><span class="line">17/04/05 14:48:23 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">17/04/05 14:48:23 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB</span><br><span class="line">17/04/05 14:48:23 INFO util.GSet: capacity      = 2^21 = 2097152 entries</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: defaultReplication         = 2</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: maxReplication             = 512</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: minReplication             = 1</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: encryptDataTransfer        = false</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: supergroup          = supergroup</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: isPermissionEnabled = true</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: HA Enabled: false</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: Append Enabled: true</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: Computing capacity for map INodeMap</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: capacity      = 2^20 = 1048576 entries</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NameNode: Caching file names occuring more than 10 times</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: Computing capacity for map cachedBlocks</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: capacity      = 2^18 = 262144 entries</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: Computing capacity for map NameNodeRetryCache</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: capacity      = 2^15 = 32768 entries</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NNConf: ACLs enabled? false</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NNConf: XAttrs enabled? true</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NNConf: Maximum size of an xattr: 16384</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSImage: Allocated new BlockPoolId: BP-885559910-172.25.0.11-1491374904248</span><br><span class="line">17/04/05 14:48:24 INFO common.Storage: Storage directory /hadoop/hfs/name has been successfully formatted.</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</span><br><span class="line">17/04/05 14:48:24 INFO util.ExitUtil: Exiting with status 0</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at mastera0.example.com/172.25.0.11</span><br><span class="line">************************************************************/</span><br><span class="line"></span><br><span class="line">[hadoop@mastera0 hadoop]$ start-all.sh</span><br><span class="line">[hadoop@mastera0 hadoop]$ mr-jobhistory-daemon.sh start historyserver</span><br><span class="line">[hadoop@mastera0 hadoop]$ hdfs dfs -mkdir -p /booboo/input </span><br><span class="line">17/04/05 15:18:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">[hadoop@mastera0 hadoop]$ ls</span><br><span class="line">cdb5  hadoop-2.5.0-cdh5.3.6  hfs</span><br><span class="line">[hadoop@mastera0 hadoop]$ touch words</span><br><span class="line">[hadoop@mastera0 hadoop]$ vim words</span><br><span class="line">[hadoop@mastera0 hadoop]$ cat words </span><br><span class="line">hello tom</span><br><span class="line">hello jack</span><br><span class="line">hello superman</span><br><span class="line">superman is me</span><br><span class="line">batman vs superman</span><br><span class="line"></span><br><span class="line">[hadoop@mastera0 hadoop]$ hdfs dfs -put words /booboo/input</span><br><span class="line">17/04/05 15:19:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line"></span><br><span class="line">[hadoop@mastera0 hadoop]$ yarn jar hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0-cdh5.3.6.jar wordcount /booboo/input /booboo/output1</span><br><span class="line">17/04/05 15:21:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">17/04/05 15:21:50 INFO client.RMProxy: Connecting to ResourceManager at /172.25.0.11:8032</span><br><span class="line">17/04/05 15:21:51 INFO input.FileInputFormat: Total input paths to process : 1</span><br><span class="line">17/04/05 15:21:51 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">17/04/05 15:21:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1491376466525_0001</span><br><span class="line">17/04/05 15:21:52 INFO impl.YarnClientImpl: Submitted application application_1491376466525_0001</span><br><span class="line">17/04/05 15:21:52 INFO mapreduce.Job: The url to track the job: http://mastera0.example.com:8088/proxy/application_1491376466525_0001/</span><br><span class="line">17/04/05 15:21:52 INFO mapreduce.Job: Running job: job_1491376466525_0001</span><br><span class="line">17/04/05 15:22:02 INFO mapreduce.Job: Job job_1491376466525_0001 running in uber mode : false</span><br><span class="line">17/04/05 15:22:02 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">17/04/05 15:22:10 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">17/04/05 15:22:16 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">17/04/05 15:22:17 INFO mapreduce.Job: Job job_1491376466525_0001 completed successfully</span><br><span class="line">17/04/05 15:22:17 INFO mapreduce.Job: Counters: 49</span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes read=94</span><br><span class="line">		FILE: Number of bytes written=206243</span><br><span class="line">		FILE: Number of read operations=0</span><br><span class="line">		FILE: Number of large read operations=0</span><br><span class="line">		FILE: Number of write operations=0</span><br><span class="line">		HDFS: Number of bytes read=177</span><br><span class="line">		HDFS: Number of bytes written=56</span><br><span class="line">		HDFS: Number of read operations=6</span><br><span class="line">		HDFS: Number of large read operations=0</span><br><span class="line">		HDFS: Number of write operations=2</span><br><span class="line">	Job Counters </span><br><span class="line">		Launched map tasks=1</span><br><span class="line">		Launched reduce tasks=1</span><br><span class="line">		Data-local map tasks=1</span><br><span class="line">		Total time spent by all maps in occupied slots (ms)=5502</span><br><span class="line">		Total time spent by all reduces in occupied slots (ms)=4424</span><br><span class="line">		Total time spent by all map tasks (ms)=5502</span><br><span class="line">		Total time spent by all reduce tasks (ms)=4424</span><br><span class="line">		Total vcore-seconds taken by all map tasks=5502</span><br><span class="line">		Total vcore-seconds taken by all reduce tasks=4424</span><br><span class="line">		Total megabyte-seconds taken by all map tasks=5634048</span><br><span class="line">		Total megabyte-seconds taken by all reduce tasks=4530176</span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=5</span><br><span class="line">		Map output records=12</span><br><span class="line">		Map output bytes=118</span><br><span class="line">		Map output materialized bytes=94</span><br><span class="line">		Input split bytes=107</span><br><span class="line">		Combine input records=12</span><br><span class="line">		Combine output records=8</span><br><span class="line">		Reduce input groups=8</span><br><span class="line">		Reduce shuffle bytes=94</span><br><span class="line">		Reduce input records=8</span><br><span class="line">		Reduce output records=8</span><br><span class="line">		Spilled Records=16</span><br><span class="line">		Shuffled Maps =1</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=1</span><br><span class="line">		GC time elapsed (ms)=42</span><br><span class="line">		CPU time spent (ms)=1550</span><br><span class="line">		Physical memory (bytes) snapshot=431570944</span><br><span class="line">		Virtual memory (bytes) snapshot=1838178304</span><br><span class="line">		Total committed heap usage (bytes)=273678336</span><br><span class="line">	Shuffle Errors</span><br><span class="line">		BAD_ID=0</span><br><span class="line">		CONNECTION=0</span><br><span class="line">		IO_ERROR=0</span><br><span class="line">		WRONG_LENGTH=0</span><br><span class="line">		WRONG_MAP=0</span><br><span class="line">[hadoop@mastera0 ~]$ hdfs namenode -format</span><br><span class="line">17/04/05 14:48:22 INFO namenode.NameNode: STARTUP_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">STARTUP_MSG: Starting NameNode</span><br><span class="line">STARTUP_MSG:   host = mastera0.example.com/172.25.0.11</span><br><span class="line">STARTUP_MSG:   args = [-format]</span><br><span class="line">STARTUP_MSG:   version = 2.5.0-cdh5.3.6</span><br><span class="line">STARTUP_MSG:   classpath = /hadoop/hadoop-2.5.0-cdh5.3.6/etc/hadoop:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/guava-11.0.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jsch-0.1.42.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-digester-1.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jets3t-0.9.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-configuration-1.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-compress-1.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/xz-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jetty-util-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/httpcore-4.2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/netty-3.6.2.Final.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-collections-3.2.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/xmlenc-0.52.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jersey-core-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-httpclient-3.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/asm-3.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-el-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-codec-1.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jersey-json-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-lang-2.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/stax-api-1.0-2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/curator-framework-2.6.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/hadoop-auth-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jsr305-1.3.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/hamcrest-core-1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/avro-1.7.6-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-net-3.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/junit-4.11.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/mockito-all-1.8.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/activation-1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/servlet-api-2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/hadoop-annotations-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jersey-server-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/httpclient-4.2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/zookeeper-3.4.5-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/curator-client-2.6.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/jetty-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/lib/commons-io-2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/hadoop-common-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/hadoop-nfs-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/common/hadoop-common-2.5.0-cdh5.3.6-tests.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/guava-11.0.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jetty-util-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jackson-core-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/asm-3.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-el-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jackson-mapper-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/jetty-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/lib/commons-io-2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/hadoop-hdfs-2.5.0-cdh5.3.6-tests.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/hdfs/hadoop-hdfs-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jline-0.9.94.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-cli-1.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/guava-11.0.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/xz-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jettison-1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jetty-util-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-client-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-core-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jackson-core-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/asm-3.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-codec-1.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-json-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-lang-2.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/guice-3.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jackson-xc-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jackson-mapper-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/activation-1.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/servlet-api-2.5.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jersey-server-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/log4j-1.2.17.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/zookeeper-3.4.5-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jackson-jaxrs-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/jetty-6.1.26.cloudera.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/lib/commons-io-2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-client-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-common-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-api-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-common-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/xz-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/asm-3.2.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/guice-3.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/javax.inject-1.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/avro-1.7.6-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.6-tests.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.0-cdh5.3.6.jar:/hadoop/hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.0-cdh5.3.6.jar:/contrib/capacity-scheduler/*.jar</span><br><span class="line">STARTUP_MSG:   build = http://github.com/cloudera/hadoop -r 6743ef286bfdd317b600adbdb154f982cf2fac7a; compiled by &#x27;jenkins&#x27; on 2015-07-28T22:14Z</span><br><span class="line">STARTUP_MSG:   java = 1.7.0_79</span><br><span class="line">************************************************************/</span><br><span class="line">17/04/05 14:48:22 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]</span><br><span class="line">17/04/05 14:48:22 INFO namenode.NameNode: createNameNode [-format]</span><br><span class="line">17/04/05 14:48:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">Formatting using clusterid: CID-954f4053-15e7-4bda-b7de-18f0cf9397f8</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: No KeyProvider found.</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: fsLock is fair:true</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: The block deletion will start around 2017 Apr 05 14:48:23</span><br><span class="line">17/04/05 14:48:23 INFO util.GSet: Computing capacity for map BlocksMap</span><br><span class="line">17/04/05 14:48:23 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">17/04/05 14:48:23 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB</span><br><span class="line">17/04/05 14:48:23 INFO util.GSet: capacity      = 2^21 = 2097152 entries</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: defaultReplication         = 2</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: maxReplication             = 512</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: minReplication             = 1</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: shouldCheckForEnoughRacks  = false</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: encryptDataTransfer        = false</span><br><span class="line">17/04/05 14:48:23 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: fsOwner             = hadoop (auth:SIMPLE)</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: supergroup          = supergroup</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: isPermissionEnabled = true</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: HA Enabled: false</span><br><span class="line">17/04/05 14:48:23 INFO namenode.FSNamesystem: Append Enabled: true</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: Computing capacity for map INodeMap</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: capacity      = 2^20 = 1048576 entries</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NameNode: Caching file names occuring more than 10 times</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: Computing capacity for map cachedBlocks</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: capacity      = 2^18 = 262144 entries</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: Retry cache on namenode is enabled</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: Computing capacity for map NameNodeRetryCache</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: VM type       = 64-bit</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB</span><br><span class="line">17/04/05 14:48:24 INFO util.GSet: capacity      = 2^15 = 32768 entries</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NNConf: ACLs enabled? false</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NNConf: XAttrs enabled? true</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NNConf: Maximum size of an xattr: 16384</span><br><span class="line">17/04/05 14:48:24 INFO namenode.FSImage: Allocated new BlockPoolId: BP-885559910-172.25.0.11-1491374904248</span><br><span class="line">17/04/05 14:48:24 INFO common.Storage: Storage directory /hadoop/hfs/name has been successfully formatted.</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid &gt;= 0</span><br><span class="line">17/04/05 14:48:24 INFO util.ExitUtil: Exiting with status 0</span><br><span class="line">17/04/05 14:48:24 INFO namenode.NameNode: SHUTDOWN_MSG: </span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at mastera0.example.com/172.25.0.11</span><br><span class="line">************************************************************/</span><br><span class="line"></span><br><span class="line">[hadoop@mastera0 hadoop]$ start-all.sh</span><br><span class="line">[hadoop@mastera0 hadoop]$ mr-jobhistory-daemon.sh start historyserver</span><br><span class="line">[hadoop@mastera0 hadoop]$ hdfs dfs -mkdir -p /booboo/input </span><br><span class="line">17/04/05 15:18:00 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">[hadoop@mastera0 hadoop]$ ls</span><br><span class="line">cdb5  hadoop-2.5.0-cdh5.3.6  hfs</span><br><span class="line">[hadoop@mastera0 hadoop]$ touch words</span><br><span class="line">[hadoop@mastera0 hadoop]$ vim words</span><br><span class="line">[hadoop@mastera0 hadoop]$ cat words </span><br><span class="line">hello tom</span><br><span class="line">hello jack</span><br><span class="line">hello superman</span><br><span class="line">superman is me</span><br><span class="line">batman vs superman</span><br><span class="line"></span><br><span class="line">[hadoop@mastera0 hadoop]$ hdfs dfs -put words /booboo/input</span><br><span class="line">17/04/05 15:19:14 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line"></span><br><span class="line">[hadoop@mastera0 hadoop]$ yarn jar hadoop-2.5.0-cdh5.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.0-cdh5.3.6.jar wordcount /booboo/input /booboo/output1</span><br><span class="line">17/04/05 15:21:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">17/04/05 15:21:50 INFO client.RMProxy: Connecting to ResourceManager at /172.25.0.11:8032</span><br><span class="line">17/04/05 15:21:51 INFO input.FileInputFormat: Total input paths to process : 1</span><br><span class="line">17/04/05 15:21:51 INFO mapreduce.JobSubmitter: number of splits:1</span><br><span class="line">17/04/05 15:21:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1491376466525_0001</span><br><span class="line">17/04/05 15:21:52 INFO impl.YarnClientImpl: Submitted application application_1491376466525_0001</span><br><span class="line">17/04/05 15:21:52 INFO mapreduce.Job: The url to track the job: http://mastera0.example.com:8088/proxy/application_1491376466525_0001/</span><br><span class="line">17/04/05 15:21:52 INFO mapreduce.Job: Running job: job_1491376466525_0001</span><br><span class="line">17/04/05 15:22:02 INFO mapreduce.Job: Job job_1491376466525_0001 running in uber mode : false</span><br><span class="line">17/04/05 15:22:02 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">17/04/05 15:22:10 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">17/04/05 15:22:16 INFO mapreduce.Job:  map 100% reduce 100%</span><br><span class="line">17/04/05 15:22:17 INFO mapreduce.Job: Job job_1491376466525_0001 completed successfully</span><br><span class="line">17/04/05 15:22:17 INFO mapreduce.Job: Counters: 49</span><br><span class="line">	File System Counters</span><br><span class="line">		FILE: Number of bytes read=94</span><br><span class="line">		FILE: Number of bytes written=206243</span><br><span class="line">		FILE: Number of read operations=0</span><br><span class="line">		FILE: Number of large read operations=0</span><br><span class="line">		FILE: Number of write operations=0</span><br><span class="line">		HDFS: Number of bytes read=177</span><br><span class="line">		HDFS: Number of bytes written=56</span><br><span class="line">		HDFS: Number of read operations=6</span><br><span class="line">		HDFS: Number of large read operations=0</span><br><span class="line">		HDFS: Number of write operations=2</span><br><span class="line">	Job Counters </span><br><span class="line">		Launched map tasks=1</span><br><span class="line">		Launched reduce tasks=1</span><br><span class="line">		Data-local map tasks=1</span><br><span class="line">		Total time spent by all maps in occupied slots (ms)=5502</span><br><span class="line">		Total time spent by all reduces in occupied slots (ms)=4424</span><br><span class="line">		Total time spent by all map tasks (ms)=5502</span><br><span class="line">		Total time spent by all reduce tasks (ms)=4424</span><br><span class="line">		Total vcore-seconds taken by all map tasks=5502</span><br><span class="line">		Total vcore-seconds taken by all reduce tasks=4424</span><br><span class="line">		Total megabyte-seconds taken by all map tasks=5634048</span><br><span class="line">		Total megabyte-seconds taken by all reduce tasks=4530176</span><br><span class="line">	Map-Reduce Framework</span><br><span class="line">		Map input records=5</span><br><span class="line">		Map output records=12</span><br><span class="line">		Map output bytes=118</span><br><span class="line">		Map output materialized bytes=94</span><br><span class="line">		Input split bytes=107</span><br><span class="line">		Combine input records=12</span><br><span class="line">		Combine output records=8</span><br><span class="line">		Reduce input groups=8</span><br><span class="line">		Reduce shuffle bytes=94</span><br><span class="line">		Reduce input records=8</span><br><span class="line">		Reduce output records=8</span><br><span class="line">		Spilled Records=16</span><br><span class="line">		Shuffled Maps =1</span><br><span class="line">		Failed Shuffles=0</span><br><span class="line">		Merged Map outputs=1</span><br><span class="line">		GC time elapsed (ms)=42</span><br><span class="line">		CPU time spent (ms)=1550</span><br><span class="line">		Physical memory (bytes) snapshot=431570944</span><br><span class="line">		Virtual memory (bytes) snapshot=1838178304</span><br><span class="line">		Total committed heap usage (bytes)=273678336</span><br><span class="line">	Shuffle Errors</span><br><span class="line">		BAD_ID=0</span><br><span class="line">		CONNECTION=0</span><br><span class="line">		IO_ERROR=0</span><br><span class="line">		WRONG_LENGTH=0</span><br><span class="line">		WRONG_MAP=0</span><br><span class="line">		WRONG_REDUCE=0</span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=70</span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=56</span><br><span class="line">[hadoop@mastera0 hadoop]$ hdfs dfs -cat /booboo/output1/part-r-00000</span><br><span class="line">17/04/05 15:25:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">batman	1</span><br><span class="line">hello	3</span><br><span class="line">is	1</span><br><span class="line">jack	1</span><br><span class="line">me	1</span><br><span class="line">superman	3</span><br><span class="line">tom	1</span><br><span class="line">vs	1</span><br><span class="line">		WRONG_REDUCE=0</span><br><span class="line">	File Input Format Counters </span><br><span class="line">		Bytes Read=70</span><br><span class="line">	File Output Format Counters </span><br><span class="line">		Bytes Written=56</span><br><span class="line">[hadoop@mastera0 hadoop]$ hdfs dfs -cat /booboo/output1/part-r-00000</span><br><span class="line">17/04/05 15:25:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</span><br><span class="line">batman	1</span><br><span class="line">hello	3</span><br><span class="line">is	1</span><br><span class="line">jack	1</span><br><span class="line">me	1</span><br><span class="line">superman	3</span><br><span class="line">tom	1</span><br><span class="line">vs	1</span><br></pre></td></tr></table></figure>
<p><img src="pic/01.png" alt="01"><br><img src="pic/02.png" alt="01"><br><img src="pic/03.png" alt="01"><br><img src="pic/04.png" alt="01"><br><img src="pic/05.png" alt="01"><br><img src="pic/06.png" alt="01"><br><img src="pic/07.png" alt="01"><br><img src="pic/08.png" alt="01"><br><img src="pic/09.png" alt="01"><br><img src="pic/10.png" alt="01"></p>

              </div>
              <footer class="article-footer">
                <time class="article-footer-updated" datetime="2022-03-22T03:27:47.576Z" itemprop="dateModified">上次更新：2022-03-22</time>
                <a href="/database/mysql/index.html" class="article-footer-next" title="概览"><span>下一页</span><i class="fa fa-chevron-right"></i></a>
              </footer>
              
<section id="comments">
  <div id="disqus_thread"></div>
</section>
<script>
  var disqus_shortname = 'www-toberoot-com';
  var disqus_url = 'http://www.toberoot.com/database/nosql/hadoop/02_operation/hadoopInstall.html';
  var disqus_title = "Hadoop Install & wordcount test";
  var disqus_config = function(){
    this.language = 'zh';
  };
  (function(){
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = 'https://go.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>

            </div>
          </div>
          <aside id="article-toc" role="navigation">
            <div id="article-toc-inner">
              
<div id="carbonads">
<span>
<span class="carbon-wrap">
<a href="https://github.com/booboowei" class="carbon-img" target="_blank" rel="noopener sponsored external nofollow noreferrer">
    <img src="https://avatars2.githubusercontent.com/u/21328020?s=460&u=88cf6127c32932188f936d05636b7b0d36783ee1&v=4"
    alt="ads via Carbon" border="0" style="max-width: 130px;">
</a>
<a href="/about/" class="carbon-text" target="_blank" rel="noopener sponsored">除了自己的无知，我什么都不知道</a>
</span>
</span>

              <strong class="sidebar-title">目录</strong>
              <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E4%BB%8B%E7%BB%8D"><span class="toc-text">环境介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E5%8C%96%E7%8E%AF%E5%A2%83%E8%84%9A%E6%9C%AC"><span class="toc-text">初始化环境脚本</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Install-JDK-amp-Hadoop"><span class="toc-text">Install JDK &amp; Hadoop</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Hadoop%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-text">Hadoop配置文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#wordcount-%E6%B5%8B%E8%AF%95"><span class="toc-text">wordcount 测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%A6%E7%BB%86%E6%93%8D%E4%BD%9C%E7%95%99%E6%A1%A3"><span class="toc-text">详细操作留档</span></a></li></ol>
              <a href="#" id="article-toc-top">回到顶部</a>
            </div>
          </aside>
        </div>
      </article>
      <aside id="sidebar" role="navigation">
  <div class="inner">
    <strong class="sidebar-title">MySQL</strong><a href="/database/mysql/index.html" class="sidebar-link">概览</a><a href="/database/mysql/booboo_mysql/index.html" class="sidebar-link">MySQL 基础</a><a href="/database/mysql/dba_mysql/index.html" class="sidebar-link">MySQL 运维实践</a><a href="/database/mysql/rds_mysql/index.html" class="sidebar-link">RDS 性能调优</a><a href="/database/mysql/security/index.html" class="sidebar-link">安全篇</a><a href="/database/mysql/awesome-tools/index.html" class="sidebar-link">工具篇</a><strong class="sidebar-title">Oracle</strong><a href="/database/oracle/index.html" class="sidebar-link">概览</a><a href="/database/oracle/ocp/index.html" class="sidebar-link">Oracle12C OCP</a><a href="/database/oracle/oracle-12c/index.html" class="sidebar-link">Oracle 12c 学习笔记</a><a href="/database/oracle/oracle-11g/index.html" class="sidebar-link">Oracle 11g 学习笔记</a><strong class="sidebar-title">NoSQL</strong><a href="/database/nosql/index.html" class="sidebar-link">概览</a><a href="/database/nosql/booboo_redis/index.html" class="sidebar-link">Redis 基础</a><a href="/database/nosql/dba_redis/index.html" class="sidebar-link">Redis 进阶</a><a href="/database/nosql/booboo_mongodb/index.html" class="sidebar-link">MongoDB 基础</a><a href="/database/nosql/hadoop/index.html" class="sidebar-link">Hadoop 基础</a><strong class="sidebar-title">TiDB</strong><a href="/database/tidb/index.html" class="sidebar-link">概览</a><a href="/database/tidb/00_tidb入门指南.html" class="sidebar-link">TiDB 入门指南</a><a href="/database/tidb/01_raft协议理解.html" class="sidebar-link">Raft协议理解</a><a href="/database/tidb/tidb_courses/index.html" class="sidebar-link">TiDB 21天课程</a>
  </div>
</aside>


    </div>
  </div>
</div>

    <footer id="footer" class="wrapper">
  <div class="inner">
    <div id="footer-copyright">
      &copy; 2022 <a href="https://github.com/hexojs/hexo/graphs/contributors" rel="external nofollow noreferrer" target="_blank">魏亚萍</a><br>
      Documentation licensed under <a href="https://choosealicense.com/licenses/agpl-3.0/" rel="external nofollow noreferrer" target="_blank">GNU AGPLv3</a><br>
      备案号：沪ICP备2020026043号
    </div>
    <div id="footer-links">
      <a href="https://github.com/BoobooWei" rel="external nofollow noreferrer" class="footer-link" target="_blank"><i class="fa fa-github-alt"></i></a>
      <a href="http://www.toberoot.com/">大宝</a><
      <a href="https://www.huangjingxue.com/" rel="external nofollow noreferrer" target="_blank">衾袭</a><
      <a href="https://husky-wu.github.io/" rel="external nofollow noreferrer" target="_blank">明夋</a><
      <a href="https://footman-ljn.github.io/" rel="external nofollow noreferrer" target="_blank">伊斯</a>
    </div>
  </div>
  <br>
  <div class="inner">
  </div>

</footer>

  </div>
  <div id="mobile-nav-dimmer"></div>
  <nav id="mobile-nav">
  <div id="mobile-nav-inner">
    <ul id="mobile-nav-list">
      <a href="/api/" class="mobile-nav-link">MySQL8.0</a><a href="/database/" class="mobile-nav-link">Database</a><a href="/devops/" class="mobile-nav-link">DevOps</a><a href="/linux/" class="mobile-nav-link">Linux</a><a href="/cloud/" class="mobile-nav-link">Cloud</a><a href="/mse/" class="mobile-nav-link">MSE</a><a href="/singapore/" class="mobile-nav-link">Singapore</a><a href="/news/" class="mobile-nav-link">News</a>
      <li class="mobile-nav-item">
        <a href="https://github.com/BoobooWei" class="mobile-nav-link" rel="external" target="_blank">GitHub</a>
      </li>
    </ul>
    
      <strong class="mobile-nav-title">MySQL</strong><a href="/database/mysql/index.html" class="mobile-nav-link">概览</a><a href="/database/mysql/booboo_mysql/index.html" class="mobile-nav-link">MySQL 基础</a><a href="/database/mysql/dba_mysql/index.html" class="mobile-nav-link">MySQL 运维实践</a><a href="/database/mysql/rds_mysql/index.html" class="mobile-nav-link">RDS 性能调优</a><a href="/database/mysql/security/index.html" class="mobile-nav-link">安全篇</a><a href="/database/mysql/awesome-tools/index.html" class="mobile-nav-link">工具篇</a><strong class="mobile-nav-title">Oracle</strong><a href="/database/oracle/index.html" class="mobile-nav-link">概览</a><a href="/database/oracle/ocp/index.html" class="mobile-nav-link">Oracle12C OCP</a><a href="/database/oracle/oracle-12c/index.html" class="mobile-nav-link">Oracle 12c 学习笔记</a><a href="/database/oracle/oracle-11g/index.html" class="mobile-nav-link">Oracle 11g 学习笔记</a><strong class="mobile-nav-title">NoSQL</strong><a href="/database/nosql/index.html" class="mobile-nav-link">概览</a><a href="/database/nosql/booboo_redis/index.html" class="mobile-nav-link">Redis 基础</a><a href="/database/nosql/dba_redis/index.html" class="mobile-nav-link">Redis 进阶</a><a href="/database/nosql/booboo_mongodb/index.html" class="mobile-nav-link">MongoDB 基础</a><a href="/database/nosql/hadoop/index.html" class="mobile-nav-link">Hadoop 基础</a><strong class="mobile-nav-title">TiDB</strong><a href="/database/tidb/index.html" class="mobile-nav-link">概览</a><a href="/database/tidb/00_tidb入门指南.html" class="mobile-nav-link">TiDB 入门指南</a><a href="/database/tidb/01_raft协议理解.html" class="mobile-nav-link">Raft协议理解</a><a href="/database/tidb/tidb_courses/index.html" class="mobile-nav-link">TiDB 21天课程</a>
    
  </div>
  <div id="mobile-lang-select-wrap">
    <span id="mobile-lang-select-label"><i class="fa fa-globe"></i><span>简体中文</span></span>
    <select id="mobile-lang-select" data-canonical="">
      
        <option value="zh-cn" selected>简体中文</option>
      
    </select>
  </div>
</nav>
  <!-- Scripts -->
<!-- Cookie -->
<script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script>
<!-- build:js build/js/main.js -->

<script src="/js/lang_select.js"></script>


<script src="/js/toc.js"></script>


<script src="/js/mobile_nav.js"></script>

<!-- endbuild -->

<!-- Algolia -->

<!-- at the end of the BODY -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
<script type="text/javascript">
document.getElementById('search-input-wrap').classList.add('on');
docsearch({
    apiKey: 'ad652bf20bcd81434ad119c8cf34722e',
    indexName: 'toberoot',
    inputSelector: '#search-input'
});
</script>

<!--   backup
<script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script>
<script type="text/javascript">
document.getElementById('search-input-wrap').classList.add('on');
docsearch({
  apiKey: 'ad652bf20bcd81434ad119c8cf34722e',
  indexName: 'toberoot',
  inputSelector: '#search-input'
});
</script>
-->

<script src="https://cdn.jsdelivr.net/npm/jquery@3.4.1/dist/jquery.slim.min.js"
    integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
    integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
    crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.min.js"
    integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
    crossorigin="anonymous"></script>
<!-- Bootstrap JS -->



</body>
</html>